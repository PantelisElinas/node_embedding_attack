{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from scipy.linalg import eigh\n",
    "from scipy import sparse\n",
    "from node_embedding_attack.utils import *\n",
    "from node_embedding_attack.embedding import *\n",
    "from node_embedding_attack.perturbation_attack import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_orig(data_dir, largest_cc=False):\n",
    "    \"\"\"Only loads the graph structure ignoring node features\"\"\"\n",
    "    g_nx = nx.read_edgelist(path=os.path.expanduser(os.path.join(data_dir, \"cora.cites\")))\n",
    "    \n",
    "    for edge in g_nx.edges(data=True):\n",
    "        edge[2]['label'] = 'cites'\n",
    "\n",
    "    if largest_cc:\n",
    "        # Select the largest connected component. For clarity we ignore isolated\n",
    "        # nodes and subgraphs; having these in the data does not prevent the\n",
    "        # algorithm from running and producing valid results.\n",
    "        g_nx_ccs = (g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx))\n",
    "        g_nx = max(g_nx_ccs, key=len)\n",
    "        print(\"Largest subgraph statistics: {} nodes, {} edges\".format(\n",
    "            g_nx.number_of_nodes(), g_nx.number_of_edges()))   \n",
    "\n",
    "    adj_matrix = nx.to_numpy_array(g_nx)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "        \n",
    "    return g_nx, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora(data_dir, largest_cc=False):\n",
    "    \"\"\"Only loads the graph structure ignoring node features\"\"\"\n",
    "    path = os.path.expanduser(os.path.join(data_dir, \n",
    "                                           \"ind.cora.graph\"))\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        G_dict = pkl.load(f, encoding=\"latin1\")\n",
    "    \n",
    "    G = nx.from_dict_of_lists(G_dict)\n",
    "    \n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "\n",
    "    return G, adj_matrix        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_citeseer_old(data_home):\n",
    "    \"\"\"Only returns the graph structure ignoring node features\"\"\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(data_home, \"citeseer.content\"),\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    df.index = df.index.map(str)\n",
    "\n",
    "    features_df = df.iloc[:, :-1]\n",
    "    labels_df = df.iloc[:, -1]\n",
    "\n",
    "    edge_list_df = pd.read_csv(\n",
    "        os.path.join(data_home, \"citeseer.cites\"), sep=r\"\\s+\", dtype=str, header=None\n",
    "    )\n",
    "\n",
    "    idx_map = {j: i for i, j in enumerate(df.index)}\n",
    "\n",
    "    H = nx.from_pandas_edgelist(edge_list_df, 0, 1)\n",
    "    G = nx.relabel.relabel_nodes(H, idx_map)\n",
    "\n",
    "    # This dataset has about 15 nodes in the edge list that don't have corresponding entries\n",
    "    # in citeseer.content, that is don't have features. We need to identify them and then remove\n",
    "    # them from the graph along with all the edges to/from them.\n",
    "    nodes_to_remove = [n for n in G.nodes() if type(n) == str]\n",
    "    print(f\"Removing {len(nodes_to_remove)} nodes from graph\")\n",
    "    G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "\n",
    "    #adj_matrix = nx.to_scipy_sparse_matrix(G, nodelist=sorted(G.nodes()), format=\"coo\")\n",
    "\n",
    "    return G, adj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_citeseer(data_home):\n",
    "    \"\"\"Only returns the graph structure ignoring node features\"\"\"\n",
    "\n",
    "    path = os.path.expanduser(os.path.join(data_home, \n",
    "                                           \"ind.citeseer.graph\"))\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        G_dict = pkl.load(f, encoding=\"latin1\")\n",
    "    \n",
    "    G = nx.from_dict_of_lists(G_dict)\n",
    "    \n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "\n",
    "    return G, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polblogs(data_home=None):\n",
    "    graph = load_dataset('data/polblogs.npz')\n",
    "    adj_matrix = graph['adj_matrix']\n",
    "    labels = graph['labels']\n",
    "\n",
    "    adj_matrix, labels = standardize(adj_matrix, labels)\n",
    "    adj_matrix = np.asarray(adj_matrix.todense())\n",
    "    G = nx.from_numpy_matrix(adj_matrix)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "    \n",
    "    # write the graph and labels to disk\n",
    "    nx.write_gpickle(G, \"polblogs_graph.gpickle\")\n",
    "    np.save(\"polblogs_labels.npy\", labels)\n",
    "    \n",
    "    return G, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pubmed(data_home):\n",
    "    \"\"\"Only returns the graph structure ignoring node features\"\"\"\n",
    "\n",
    "    path = os.path.expanduser(os.path.join(data_home, \n",
    "                                           \"ind.pubmed.graph\"))\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        G_dict = pkl.load(f, encoding=\"latin1\")\n",
    "    \n",
    "    G = nx.from_dict_of_lists(G_dict)\n",
    "    \n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "\n",
    "    return G, adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"polblogs\"  # one of cora, citeseer, polblogs, pubmed\n",
    "load_data = load_cora\n",
    "if dataset==\"cora\":\n",
    "    data_dir = \"~/data/cora\"\n",
    "elif dataset == \"citeseer\":\n",
    "    data_dir = \"~/data/citeseer/\"\n",
    "    load_data = load_citeseer\n",
    "elif dataset == \"polblogs\":\n",
    "    data_dir = None\n",
    "    load_data = load_polblogs\n",
    "elif dataset == \"pubmed\":\n",
    "    data_dir = \"~/data/pubmed/\"\n",
    "    load_data = load_citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nx, adj_matrix = load_data(data_dir)\n",
    "n_nodes = adj_matrix.shape[0]\n",
    "# The example code selects the largest component but we won't do that\n",
    "# here. The question is, does this effect the quality of attacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1222, 1222), 1222, 16717)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix.shape, n_nodes, g_nx.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(g_nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flips = 1000\n",
    "dim = 32\n",
    "window_size = 5\n",
    "#attack_method = \"add\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Store attacked graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_graph(adj_matrix, n_flips, dim, \n",
    "                 window_size, seed=0, method=\"add\"):\n",
    "    \"\"\"Method for attacking a graph by adding or removing edges\"\"\"\n",
    "    if method==\"add\":\n",
    "        candidates = generate_candidates_addition(adj_matrix=adj_matrix,\n",
    "                                                  n_candidates=n_flips, \n",
    "                                                  seed=seed)\n",
    "    else:\n",
    "        candidates = generate_candidates_removal(adj_matrix=adj_matrix, \n",
    "                                                 seed=seed)\n",
    "        \n",
    "    our_flips = perturbation_top_flips(adj_matrix, \n",
    "                                       candidates, \n",
    "                                       n_flips, \n",
    "                                       dim, \n",
    "                                       window_size)\n",
    "    #\n",
    "    A = np.array(adj_matrix.todense())\n",
    "    \n",
    "    A_flipped = A.copy()\n",
    "    A_flipped[our_flips[:, 0], our_flips[:, 1]] = 1 - A[our_flips[:, 0], our_flips[:, 1]]\n",
    "    A_flipped[our_flips[:, 1], our_flips[:, 0]] = 1 - A[our_flips[:, 1], our_flips[:, 0]]\n",
    "    \n",
    "    return A_flipped  # The attacked adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save attacked graph to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attacked_datasets/polblogs/attack\n"
     ]
    }
   ],
   "source": [
    "ele = 'attack'\n",
    "#corrupted_A = corrupt_adjacency(A, ele, l)\n",
    "dir_name = os.path.join(\"attacked_datasets\", \n",
    "                        dataset, \n",
    "                        ele)\n",
    "print(dir_name)\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [0, 42, 10003, 918358, 63947, 9123, 43218, 90, 300134, 1239876]\n",
    "if dataset==\"cora\":\n",
    "    num_flips = [ -2000, -1000, -500, 500, 1000, 2000, 5000 ]\n",
    "elif dataset==\"citeseer\":\n",
    "    num_flips = [ -2000, -1000, -500, 500, 1000, 2000, 5000 ]\n",
    "elif dataset==\"polblogs\":\n",
    "    num_flips = [ -2000, -1000, -500, 500, 1000, 2000, 5000 ]\n",
    "elif dataset==\"pubmed\":\n",
    "    num_flips = [ -20000, -10000, -5000, -2000, 2000, 5000, 10000, 20000, 40000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for n_flips=-2000\n",
      "file_name: polblogs_attack_remove_2000_v_0\n",
      "file_name: polblogs_attack_remove_2000_v_1\n",
      "file_name: polblogs_attack_remove_2000_v_2\n",
      "file_name: polblogs_attack_remove_2000_v_3\n",
      "file_name: polblogs_attack_remove_2000_v_4\n",
      "file_name: polblogs_attack_remove_2000_v_5\n",
      "file_name: polblogs_attack_remove_2000_v_6\n",
      "file_name: polblogs_attack_remove_2000_v_7\n",
      "file_name: polblogs_attack_remove_2000_v_8\n",
      "file_name: polblogs_attack_remove_2000_v_9\n",
      "Calculating for n_flips=-1000\n",
      "file_name: polblogs_attack_remove_1000_v_0\n",
      "file_name: polblogs_attack_remove_1000_v_1\n",
      "file_name: polblogs_attack_remove_1000_v_2\n",
      "file_name: polblogs_attack_remove_1000_v_3\n",
      "file_name: polblogs_attack_remove_1000_v_4\n",
      "file_name: polblogs_attack_remove_1000_v_5\n",
      "file_name: polblogs_attack_remove_1000_v_6\n",
      "file_name: polblogs_attack_remove_1000_v_7\n",
      "file_name: polblogs_attack_remove_1000_v_8\n",
      "file_name: polblogs_attack_remove_1000_v_9\n",
      "Calculating for n_flips=-500\n",
      "file_name: polblogs_attack_remove_500_v_0\n",
      "file_name: polblogs_attack_remove_500_v_1\n",
      "file_name: polblogs_attack_remove_500_v_2\n",
      "file_name: polblogs_attack_remove_500_v_3\n",
      "file_name: polblogs_attack_remove_500_v_4\n",
      "file_name: polblogs_attack_remove_500_v_5\n",
      "file_name: polblogs_attack_remove_500_v_6\n",
      "file_name: polblogs_attack_remove_500_v_7\n",
      "file_name: polblogs_attack_remove_500_v_8\n",
      "file_name: polblogs_attack_remove_500_v_9\n",
      "Calculating for n_flips=500\n",
      "file_name: polblogs_attack_add_500_v_0\n",
      "file_name: polblogs_attack_add_500_v_1\n",
      "file_name: polblogs_attack_add_500_v_2\n",
      "file_name: polblogs_attack_add_500_v_3\n",
      "file_name: polblogs_attack_add_500_v_4\n",
      "file_name: polblogs_attack_add_500_v_5\n",
      "file_name: polblogs_attack_add_500_v_6\n",
      "file_name: polblogs_attack_add_500_v_7\n",
      "file_name: polblogs_attack_add_500_v_8\n",
      "file_name: polblogs_attack_add_500_v_9\n",
      "Calculating for n_flips=1000\n",
      "file_name: polblogs_attack_add_1000_v_0\n",
      "file_name: polblogs_attack_add_1000_v_1\n",
      "file_name: polblogs_attack_add_1000_v_2\n",
      "file_name: polblogs_attack_add_1000_v_3\n",
      "file_name: polblogs_attack_add_1000_v_4\n",
      "file_name: polblogs_attack_add_1000_v_5\n",
      "file_name: polblogs_attack_add_1000_v_6\n",
      "file_name: polblogs_attack_add_1000_v_7\n",
      "file_name: polblogs_attack_add_1000_v_8\n",
      "file_name: polblogs_attack_add_1000_v_9\n",
      "Calculating for n_flips=2000\n",
      "file_name: polblogs_attack_add_2000_v_0\n",
      "file_name: polblogs_attack_add_2000_v_1\n",
      "file_name: polblogs_attack_add_2000_v_2\n",
      "file_name: polblogs_attack_add_2000_v_3\n",
      "file_name: polblogs_attack_add_2000_v_4\n",
      "file_name: polblogs_attack_add_2000_v_5\n",
      "file_name: polblogs_attack_add_2000_v_6\n",
      "file_name: polblogs_attack_add_2000_v_7\n",
      "file_name: polblogs_attack_add_2000_v_8\n",
      "file_name: polblogs_attack_add_2000_v_9\n",
      "Calculating for n_flips=5000\n",
      "file_name: polblogs_attack_add_5000_v_0\n",
      "file_name: polblogs_attack_add_5000_v_1\n",
      "file_name: polblogs_attack_add_5000_v_2\n",
      "file_name: polblogs_attack_add_5000_v_3\n",
      "file_name: polblogs_attack_add_5000_v_4\n",
      "file_name: polblogs_attack_add_5000_v_5\n",
      "file_name: polblogs_attack_add_5000_v_6\n",
      "file_name: polblogs_attack_add_5000_v_7\n",
      "file_name: polblogs_attack_add_5000_v_8\n",
      "file_name: polblogs_attack_add_5000_v_9\n"
     ]
    }
   ],
   "source": [
    "for n_flips in num_flips:\n",
    "    print(f\"Calculating for n_flips={n_flips}\")\n",
    "    for i, seed in enumerate(seeds):\n",
    "        if n_flips < 0:\n",
    "            method = \"remove\"\n",
    "            n_flips_ = -n_flips\n",
    "        else:\n",
    "            n_flips_ = n_flips\n",
    "            method = \"add\"\n",
    "        A_flipped = attack_graph(adj_matrix=adj_matrix, \n",
    "                                 n_flips=n_flips_, \n",
    "                                 dim=dim, \n",
    "                                 window_size=window_size, \n",
    "                                 method=method, \n",
    "                                 seed=seed)\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "        file_name = dataset + \"_\" + ele + \"_\"+method+\"_\"+str(n_flips_)+\"_v_\"+str(i)\n",
    "        print(f\"file_name: {file_name}\")\n",
    "        #np.save(os.path.join(dir_name,file_name), A_flipped)\n",
    "\n",
    "        graph = nx.from_numpy_array(A_flipped)\n",
    "        file_name += \".gpickle\"\n",
    "        nx.write_gpickle(graph, os.path.join(dir_name, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Seed\n",
    "\n",
    "Effect of seed on attacked graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flips = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flipped_1 = attack_graph(adj_matrix, \n",
    "                           n_flips, \n",
    "                           dim, \n",
    "                           window_size, seed=0, method=\"add\")\n",
    "\n",
    "a_flipped_2 = attack_graph(adj_matrix, \n",
    "                           n_flips, \n",
    "                           dim, \n",
    "                           window_size, seed=42, method=\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33321, 33321)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a_flipped_1 == 1), np.sum(a_flipped_2 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nx_1 = nx.convert_matrix.from_numpy_array(a_flipped_1)\n",
    "g_nx_2 = nx.convert_matrix.from_numpy_array(a_flipped_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16727, 16727)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It should be g_nx.number_of_edges() + n_flips\n",
    "g_nx_1.number_of_edges(), g_nx_2.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the two adjacency matrix symmetric? If so, then the difference\n",
    "# between the matrix and its transpose should be 0\n",
    "np.sum(a_flipped_1-a_flipped_1.T), np.sum(a_flipped_2-a_flipped_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If 0 then the two matrices are exactly the same.\n",
    "np.sum((a_flipped_1-a_flipped_2) != 0)\n",
    "#np.sum(np.abs(a_flipped_1-a_flipped_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_flipped_1[a_flipped_1 != a_flipped_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_flipped_2[a_flipped_1 != a_flipped_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2\n"
     ]
    }
   ],
   "source": [
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "structure-learning",
   "language": "python",
   "name": "structure-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
