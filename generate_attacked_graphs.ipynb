{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from scipy import sparse\n",
    "from node_embedding_attack.utils import *\n",
    "from node_embedding_attack.embedding import *\n",
    "from node_embedding_attack.perturbation_attack import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora(data_dir, largest_cc=False):\n",
    "    \"\"\"Only loads the graph structure ignoring node features\"\"\"\n",
    "    g_nx = nx.read_edgelist(path=os.path.expanduser(os.path.join(data_dir, \"cora.cites\")))\n",
    "    \n",
    "    for edge in g_nx.edges(data=True):\n",
    "        edge[2]['label'] = 'cites'\n",
    "\n",
    "    if largest_cc:\n",
    "        # Select the largest connected component. For clarity we ignore isolated\n",
    "        # nodes and subgraphs; having these in the data does not prevent the\n",
    "        # algorithm from running and producing valid results.\n",
    "        g_nx_ccs = (g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx))\n",
    "        g_nx = max(g_nx_ccs, key=len)\n",
    "        print(\"Largest subgraph statistics: {} nodes, {} edges\".format(\n",
    "            g_nx.number_of_nodes(), g_nx.number_of_edges()))   \n",
    "\n",
    "    adj_matrix = nx.to_numpy_array(g_nx)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)\n",
    "        \n",
    "    return g_nx, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_citeseer(data_home):\n",
    "    \"\"\"Only returns the graph structure ignoring node features\"\"\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(data_home, \"citeseer.content\"),\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    df.index = df.index.map(str)\n",
    "\n",
    "    features_df = df.iloc[:, :-1]\n",
    "    labels_df = df.iloc[:, -1]\n",
    "\n",
    "    edge_list_df = pd.read_csv(\n",
    "        os.path.join(data_home, \"citeseer.cites\"), sep=r\"\\s+\", dtype=str, header=None\n",
    "    )\n",
    "\n",
    "    idx_map = {j: i for i, j in enumerate(df.index)}\n",
    "\n",
    "    H = nx.from_pandas_edgelist(edge_list_df, 0, 1)\n",
    "    G = nx.relabel.relabel_nodes(H, idx_map)\n",
    "\n",
    "    # This dataset has about 15 nodes in the edge list that don't have corresponding entries\n",
    "    # in citeseer.content, that is don't have features. We need to identify them and then remove\n",
    "    # them from the graph along with all the edges to/from them.\n",
    "    nodes_to_remove = [n for n in G.nodes() if type(n) == str]\n",
    "    G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    adj_matrix = nx.to_scipy_sparse_matrix(G, nodelist=sorted(G.nodes()), format=\"coo\")\n",
    "\n",
    "    return G, adj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_dir = os.path.expanduser(\"~/data/cora/\")\n",
    "    cora_location = os.path.expanduser(os.path.join(data_dir, \"cora.cites\"))\n",
    "    g_nx = nx.read_edgelist(path=cora_location)\n",
    "    adj_matrix = nx.to_numpy_array(g_nx)\n",
    "    adj_matrix = sparse.csr_matrix(adj_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cora\"  # or citeseer\n",
    "load_data = load_cora\n",
    "if dataset==\"cora\":\n",
    "    data_dir = \"~/data/cora\"\n",
    "elif dataset == \"citeseer\":\n",
    "    data_dir = \"~/data/citeseer/\"\n",
    "    load_data = load_citeseer\n",
    "# How about polblogs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nx, adj_matrix = load_data(data_dir)\n",
    "n_nodes = adj_matrix.shape[0]\n",
    "# The example code selects the largest component but we won't do that\n",
    "# here. The question is, does this effect the quality of attacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), 2708)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix.shape, n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    graph = load_dataset('data/cora.npz')\n",
    "    adj_matrix = graph['adj_matrix']\n",
    "    labels = graph['labels']\n",
    "\n",
    "    adj_matrix, labels = standardize(adj_matrix, labels)\n",
    "    n_nodes = adj_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flips = 1000\n",
    "dim = 32\n",
    "window_size = 5\n",
    "attack_method = \"add\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Store attacked graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_graph(adj_matrix, n_flips, dim, \n",
    "                 window_size, seed=0, method=\"add\"):\n",
    "    \"\"\"Method for attacking a graph by adding or removing edges\"\"\"\n",
    "    if method==\"add\":\n",
    "        candidates = generate_candidates_addition(adj_matrix=adj_matrix,\n",
    "                                                  n_candidates=n_flips, \n",
    "                                                  seed=seed)\n",
    "    else:\n",
    "        candidates = generate_candidates_removal(adj_matrix=adj_matrix, \n",
    "                                                 seed=seed)\n",
    "        \n",
    "    our_flips = perturbation_top_flips(adj_matrix, \n",
    "                                       candidates, \n",
    "                                       n_flips, \n",
    "                                       dim, \n",
    "                                       window_size)\n",
    "    #\n",
    "    A = np.array(adj_matrix.todense())\n",
    "    \n",
    "    A_flipped = A.copy()\n",
    "    A_flipped[candidates[:, 0], candidates[:, 1]] = 1 - A[candidates[:, 0], candidates[:, 1]]\n",
    "    A_flipped[candidates[:, 1], candidates[:, 0]] = 1 - A[candidates[:, 1], candidates[:, 0]]\n",
    "    \n",
    "    return A_flipped  # The attacked adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_flipped = attack_graph(adj_matrix, \n",
    "                         n_flips, \n",
    "                         dim, \n",
    "                         window_size, \n",
    "                         seed=0, \n",
    "                         method=attack_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save attacked graph to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attacked_datasets/cora/attack/add\n"
     ]
    }
   ],
   "source": [
    "ele = 'attack'\n",
    "#corrupted_A = corrupt_adjacency(A, ele, l)\n",
    "dir_name = os.path.join(\"attacked_datasets\", \n",
    "                        dataset, \n",
    "                        ele, attack_method )\n",
    "print(dir_name)\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name: cora_attack_add_1000_v1\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "file_name = dataset + \"_\" + ele + \"_\"+attack_method+\"_\"+str(n_flips)+\"_v\"+str(i)\n",
    "print(f\"file_name: {file_name}\")\n",
    "np.save(os.path.join(dir_name,file_name), A_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_flips = [ -2000, -1000, -500, 500, 1000, 2000, 5000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for n_flips=-2000\n",
      "file_name: cora_attack_add_2000_remove\n",
      "Calculating for n_flips=-1000\n",
      "file_name: cora_attack_add_1000_remove\n",
      "Calculating for n_flips=-500\n",
      "file_name: cora_attack_add_500_remove\n",
      "Calculating for n_flips=500\n",
      "file_name: cora_attack_add_500_add\n",
      "Calculating for n_flips=1000\n",
      "file_name: cora_attack_add_1000_add\n",
      "Calculating for n_flips=2000\n",
      "file_name: cora_attack_add_2000_add\n",
      "Calculating for n_flips=5000\n",
      "file_name: cora_attack_add_5000_add\n"
     ]
    }
   ],
   "source": [
    "for n_flips in num_flips:\n",
    "    print(f\"Calculating for n_flips={n_flips}\")\n",
    "    if n_flips < 0:\n",
    "        method = \"remove\"\n",
    "        n_flips = -n_flips\n",
    "    else:\n",
    "        method = \"add\"\n",
    "    A_flipped = attack_graph(adj_matrix=adj_matrix, \n",
    "                             n_flips=n_flips, \n",
    "                             dim=dim, \n",
    "                             window_size=window_size, \n",
    "                             method=method, \n",
    "                             seed=0)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    file_name = dataset + \"_\" + ele + \"_\"+attack_method+\"_\"+str(n_flips)+\"_\"+method #+\"_v\"+str(i)\n",
    "    print(f\"file_name: {file_name}\")\n",
    "    np.save(os.path.join(dir_name,file_name), A_flipped)\n",
    "    \n",
    "    graph = nx.from_numpy_array(A_flipped)\n",
    "    file_name += \".gpickle\"\n",
    "    nx.write_gpickle(graph, os.path.join(dir_name, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 2708)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (link-prediction)",
   "language": "python",
   "name": "link-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
